datamodeldorisconstr:
  driver_class_name: com.mysql.jdbc.Driver
  password: root123
  url: jdbc:mysql://192.168.11.134:9030/dmp_olap?useUnicode=true&characterEncoding=utf8&allowMultiQueries=true&useSSL=false
  username: root

external-table-link: '"host" = "192.168.21.21","port" = "5432","user" = "postgres","password"
  = "postgres123","database" = "dmp_dw"'

nifi:
  username: fiskadmin
  password: Password0101!
  basePath: https://192.168.21.21:8023/nifi-api
  token: Bearer eyJhbGciOiJIUzI1NiJ9.eyJqdGkiOiI2NjU3MDI5YjQxMTc0NzdhOGMwMDExY2NmMzg2ZmYzZSIsInVzZXIiOiJ7XCJpZFwiOjE5LFwidXNlckFjY291bnRcIjpcIm5pZmnmjqXlj6N0b2tlblwifSIsImlkIjoiMTkifQ.UrYWOvRq6IqQ5pep6uCTYlE-kG_5zc7Yl6VgeYupPeU
  Enable-Authentication: 0
  kerberos:
    Keytab: /opt/fidata/java/fisk-task-center/kafka.keytab
    login:
      config: /opt/fidata/java/fisk-task-center/kafka-jaas.conf
    krb5:
      conf: /opt/fidata/java/fisk-task-center/krb5.conf
  kerberosprincipal: kafka/admin@AUTOEXPR.COM
  pipeline:
    topicName: my-topic
    waitTime: 10
    maxTime: 10800
    operation-interval: 1000
    number-of-operations: 5
    data-governance-url: http://192.168.21.21:8083
    dispatch-email-url-prefix: http://192.168.21.21:82
nifi-ConcurrentTasks: 3
nifi-FetchSize: 30000
nifi-MaxRowsPerFlowFile: 10000
nifi-OutputBatchSize: 1
fiData-data-ods-source: 2
fiData-data-dw-source: 1
fiData-data-mdm-source: 3
# 是否调用数据质量接口
nifi-data-security-enable: true
# consumeServer启动控制
consumer-server-enable: true
pgsql-datamodel:
  driverClassName: com.microsoft.sqlserver.jdbc.SQLServerDriver
  password: Password01!
  url: jdbc:sqlserver://192.168.11.133:1433;DatabaseName=dmp_ods;encrypt=true;trustServerCertificate=true
  username: sa
  ip: 192.168.11.133
  dbName: dmp_dw
pgsql-mdm:
  password: postgres123
  url: jdbc:postgresql://192.168.21.21:5432/dmp_mdm?stringtype=unspecified
  username: postgres
  type: PG

sftp-rsa-upload:
  userName: root
  password: Password01!
  rsaPath: null
  host: 192.168.21.21
  port: 22

server:
  port: 8099
spring:
  application:
    name: task-center
  datasource:
    dynamic:
      datasource:
        datainputdb:
          driver-class-name: com.mysql.jdbc.Driver
          password: root123
          url: jdbc:mysql://192.168.21.21:3306/dmp_datainput_db?useUnicode=true&characterEncoding=utf8&allowMultiQueries=true&useSSL=false
          username: root
        taskdb:
          driver-class-name: com.mysql.jdbc.Driver
          password: root123
          url: jdbc:mysql://192.168.21.21:3306/dmp_task_db?useUnicode=true&characterEncoding=utf8&allowMultiQueries=true&useSSL=false
          username: root
      primary: taskdb
      strict: false
  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
  kafka:
    consumer:
      bootstrap-servers: localhost:9092
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      session:
        timeout:
          ms: 600000
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      acks: all
      bootstrap-servers: localhost:9092
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      retries: 3
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
  redis:
    host: 192.168.21.21
    password: test123456
mybatis-plus:
  configuration:
    cache-enabled: true
pipeline-async-switch: true
